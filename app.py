import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
from sklearn.ensemble import RandomForestClassifier
import tempfile
import os
import time
from datetime import datetime
import collections
import pickle
import torch
import torch.nn as nn

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Gesture Recognition",
    page_icon="üëã",
    layout="wide"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("Gesture Recognition")
st.write("This system recognizes 5 gestures: thumbs up, palm, fist, pointing finger, victory sign (V)")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaPipe Hands
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∂–µ—Å—Ç–æ–≤
GESTURE_CLASSES = ["Thumbs Up", "Palm", "Fist", "Pointing", "Victory"]

# –ö–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–µ–π –¥–ª—è PyTorch
class CNNModel(nn.Module):
    def __init__(self, num_classes=5):
        super(CNNModel, self).__init__()
        
        # –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        self.fc_layers = nn.Sequential(
            nn.Linear(128 * 16 * 16, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –ø–ª–æ—Å–∫–∏–π –≤–µ–∫—Ç–æ—Ä
        x = self.fc_layers(x)
        return x

class LSTMModel(nn.Module):
    def __init__(self, input_size=63, hidden_size=128, num_layers=1, num_classes=5, dropout_rate=0.3):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM —Å–ª–æ–∏
        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers=1, 
                            batch_first=True, bidirectional=True)
        self.dropout1 = nn.Dropout(dropout_rate)
        
        # –í—Ç–æ—Ä–æ–π LSTM –∏–º–µ–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä, —Ä–∞–≤–Ω—ã–π —É–¥–≤–æ–µ–Ω–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–∑-–∑–∞ –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç–∏
        self.lstm2 = nn.LSTM(hidden_size*2, hidden_size, num_layers=1, 
                            batch_first=True, bidirectional=False)
        self.dropout2 = nn.Dropout(dropout_rate)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
        self.layer_norm = nn.LayerNorm(hidden_size)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.fc1 = nn.Linear(hidden_size, 128)
        self.relu = nn.ReLU()
        self.dropout3 = nn.Dropout(dropout_rate)
        self.fc2 = nn.Linear(128, num_classes)
    
    def forward(self, x):
        # –ü–µ—Ä–≤—ã–π LSTM —Å–ª–æ–π (–¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π)
        out, _ = self.lstm1(x)
        out = self.dropout1(out)
        
        # –í—Ç–æ—Ä–æ–π LSTM —Å–ª–æ–π
        out, _ = self.lstm2(out)
        out = self.dropout2(out)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —à–∞–≥–∞
        out = out[:, -1, :]
        out = self.layer_norm(out)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        out = self.fc1(out)
        out = self.relu(out)
        out = self.dropout3(out)
        out = self.fc2(out)
        
        return out

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
@st.cache_resource
def load_models():
    models = {}
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ Random Forest
    try:
        with open('models/random_forest_model.pkl', 'rb') as f:
            rf_model, label_encoder = pickle.load(f)
        models["rf"] = (rf_model, label_encoder)
        print("Random Forest –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Random Forest: {e}")
        models["rf"] = None
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ CNN
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–ª–∞—Å—Å–∞—Ö
        with open('models/class_info.pkl', 'rb') as f:
            class_info = pickle.load(f)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ CNN
        cnn_model = CNNModel(num_classes=len(class_info["classes"]))
        cnn_model.load_state_dict(torch.load('models/cnn_model.pth', map_location=torch.device('cpu')))
        cnn_model.eval()  # –ü–µ—Ä–µ–≤–æ–¥ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
        models["cnn"] = (cnn_model, class_info["classes"])
        print("CNN –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CNN: {e}")
        models["cnn"] = None
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ LSTM
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ LSTM
        lstm_model = LSTMModel(input_size=63, hidden_size=128, num_layers=1, num_classes=len(class_info["classes"]), dropout_rate=0.3)
        lstm_model.load_state_dict(torch.load('models/lstm_model.pth', map_location=torch.device('cpu')))
        lstm_model.eval()  # –ü–µ—Ä–µ–≤–æ–¥ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
        models["lstm"] = (lstm_model, class_info["classes"])
        print("LSTM –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LSTM: {e}")
        models["lstm"] = None
    
    return models

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
MODELS = load_models()

# –ö–ª–∞—Å—Å –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
class PredictionStabilizer:
    def __init__(self, window_size=10, threshold=0.6):
        self.window_size = window_size
        self.threshold = threshold
        self.predictions = collections.deque(maxlen=window_size)
        self.current_prediction = "Not detected"
        self.current_confidence = 0.0
        
    def update(self, new_prediction, new_confidence):
        # –ï—Å–ª–∏ –Ω–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ - "Not detected" –∏–ª–∏ "Error", –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if new_prediction in ["Not detected", "Error"]:
            if len(self.predictions) == 0:
                self.current_prediction = new_prediction
                self.current_confidence = new_confidence
            return self.current_prediction, self.current_confidence
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.predictions.append(new_prediction)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction_counts = collections.Counter(self.predictions)
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        most_common = prediction_counts.most_common(1)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–º–µ–Ω—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        if most_common:
            prediction, count = most_common[0]
            confidence_ratio = count / len(self.predictions)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, –µ—Å–ª–∏ —á–∞—Å—Ç–æ—Ç–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–æ—Ä–æ–≥
            if confidence_ratio >= self.threshold:
                self.current_prediction = prediction
                self.current_confidence = confidence_ratio
        
        return self.current_prediction, self.current_confidence
        
    def clear(self):
        self.predictions.clear()
        self.current_prediction = "Not detected"
        self.current_confidence = 0.0

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä—É–∫–∏ —Å –ø–æ–º–æ—â—å—é MediaPipe
def extract_hand_features(image):
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = hands.process(image_rgb)
    
    features = []
    
    if results.multi_hand_landmarks:
        hand_landmarks = results.multi_hand_landmarks[0]
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –≤—Å–µ—Ö 21 —Ç–æ—á–µ–∫ —Ä—É–∫–∏
        for landmark in hand_landmarks.landmark:
            features.extend([landmark.x, landmark.y, landmark.z])
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏
        for i in range(21):
            for j in range(i+1, 21):
                x1, y1 = hand_landmarks.landmark[i].x, hand_landmarks.landmark[i].y
                x2, y2 = hand_landmarks.landmark[j].x, hand_landmarks.landmark[j].y
                distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
                features.append(distance)
        
        return features, hand_landmarks
    
    return None, None

# –ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è LSTM
class LandmarkHistory:
    def __init__(self, max_length=15):
        self.max_length = max_length
        self.landmarks_history = collections.deque(maxlen=max_length)
        
    def add(self, landmarks):
        self.landmarks_history.append(landmarks)
        
    def get_sequence(self):
        if len(self.landmarks_history) < self.max_length:
            return None
        return np.array(list(self.landmarks_history))
        
    def clear(self):
        self.landmarks_history.clear()

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é –∂–µ—Å—Ç–æ–≤
def approach_1_random_forest(features):
    """–ü–æ–¥—Ö–æ–¥ 1: –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π"""
    try:
        if MODELS["rf"] is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
            rf_model, label_encoder = MODELS["rf"]
            prediction_idx = rf_model.predict([features])[0]
            prediction = label_encoder.inverse_transform([prediction_idx])[0]
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            probabilities = rf_model.predict_proba([features])[0]
            confidence = probabilities[prediction_idx]
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–º—è –∂–µ—Å—Ç–∞ –∫ —Ñ–æ—Ä–º–∞—Ç—É –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            prediction = prediction.replace('_', ' ').title()
            
            return prediction, confidence
        else:
            # –°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            seed = int(sum(features[:5]) * 1000) % 100000
            np.random.seed(seed)
            
            gesture_list = ["Thumbs Up", "Palm", "Fist", "Pointing", "Victory"]
            prediction = gesture_list[np.random.randint(0, 5)]
            confidence = np.random.uniform(0.7, 0.99)
            
            return prediction, confidence
    except Exception as e:
        st.error(f"Error in approach 1: {e}")
        return "Error", 0

def approach_2_cnn(image, hand_landmarks):
    """–ü–æ–¥—Ö–æ–¥ 2: –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        if MODELS["cnn"] is not None and hand_landmarks:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
            cnn_model, classes = MODELS["cnn"]
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è CNN
            h, w, _ = image.shape
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–µ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ –¥–ª—è —Ä—É–∫–∏
            x_min, y_min = 1, 1
            x_max, y_max = 0, 0
            
            for landmark in hand_landmarks.landmark:
                x_min = min(x_min, landmark.x)
                y_min = min(y_min, landmark.y)
                x_max = max(x_max, landmark.x)
                y_max = max(y_max, landmark.y)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø
            padding = 0.1
            x_min = max(0, x_min - padding)
            y_min = max(0, y_min - padding)
            x_max = min(1, x_max + padding)
            y_max = min(1, y_max + padding)
            
            x_min, y_min = int(x_min * w), int(y_min * h)
            x_max, y_max = int(x_max * w), int(y_max * h)
            
            # –û–±—Ä–µ–∑–∫–∞ –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if x_min >= x_max or y_min >= y_max or x_min < 0 or y_min < 0 or x_max > w or y_max > h:
                hand_crop = cv2.resize(image, (128, 128))
            else:
                hand_crop = image[y_min:y_max, x_min:x_max]
                hand_crop = cv2.resize(hand_crop, (128, 128))
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            hand_crop = hand_crop / 255.0
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ (batch, channels, height, width)
            hand_crop = np.transpose(hand_crop, (2, 0, 1))
            hand_crop = np.expand_dims(hand_crop, axis=0)
            hand_crop_tensor = torch.FloatTensor(hand_crop)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = cnn_model(hand_crop_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
                prediction_idx = torch.argmax(probabilities).item()
                confidence = probabilities[prediction_idx].item()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–º—è –∂–µ—Å—Ç–∞ –∫ —Ñ–æ—Ä–º–∞—Ç—É –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            prediction = classes[prediction_idx].replace('_', ' ').title()
            
            return prediction, confidence
        else:
            # –°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            if hand_landmarks:
                coords = [hand_landmarks.landmark[i].x + hand_landmarks.landmark[i].y for i in range(5)]
                seed = int(sum(coords) * 1000) % 100000
                np.random.seed(seed)
            
            gesture_list = ["Thumbs Up", "Palm", "Fist", "Pointing", "Victory"]
            prediction = gesture_list[np.random.randint(0, 5)]
            confidence = np.random.uniform(0.6, 0.95)
            
            return prediction, confidence
    except Exception as e:
        st.error(f"Error in approach 2: {e}")
        return "Error", 0

def approach_3_lstm(landmark_sequence):
    """–ü–æ–¥—Ö–æ–¥ 3: LSTM –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö"""
    try:
        if MODELS["lstm"] is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
            lstm_model, classes = MODELS["lstm"]
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∫–µ–π–ª–µ—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            scaler = None
            try:
                with open('models/lstm_scaler.pkl', 'rb') as f:
                    scaler = pickle.load(f)
            except Exception as e:
                print(f"–°–∫–µ–π–ª–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {e}")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ —Å–∫–µ–π–ª–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω
            if scaler is not None:
                # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                seq_length, num_features = landmark_sequence.shape
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 2D –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
                sequence_reshaped = landmark_sequence.reshape(seq_length * num_features)
                sequence_normalized = scaler.transform(sequence_reshaped.reshape(-1, num_features))
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –∏—Å—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ
                landmark_sequence = sequence_normalized
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–Ω–∑–æ—Ä
            sequence_tensor = torch.FloatTensor(landmark_sequence).unsqueeze(0)  # –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = lstm_model(sequence_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
                prediction_idx = torch.argmax(probabilities).item()
                confidence = probabilities[prediction_idx].item()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–º—è –∂–µ—Å—Ç–∞ –∫ —Ñ–æ—Ä–º–∞—Ç—É –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            prediction = classes[prediction_idx].replace('_', ' ').title()
            
            return prediction, confidence
        else:
            # –°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            last_features = landmark_sequence[-1]
            seed = int(sum(last_features[:5]) * 1000) % 100000
            np.random.seed(seed)
            
            gesture_list = ["Thumbs Up", "Palm", "Fist", "Pointing", "Victory"]
            prediction = gesture_list[np.random.randint(0, 5)]
            confidence = np.random.uniform(0.65, 0.97)
            
            return prediction, confidence
    except Exception as e:
        st.error(f"Error in approach 3: {e}")
        return "Error", 0

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
def display_results(image, hand_landmarks, prediction1, confidence1, prediction2, confidence2, prediction3, confidence3, evaluation_mode=False, current_gesture=None):
    h, w, c = image.shape
    
    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –º–µ—Ç–æ–∫ —Ä—É–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã
    if hand_landmarks:
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mp_drawing.draw_landmarks(
            image_rgb, 
            hand_landmarks, 
            mp_hands.HAND_CONNECTIONS
        )
        image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    cv2.putText(image, f"RF: {prediction1} ({confidence1:.2f})", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    cv2.putText(image, f"CNN: {prediction2} ({confidence2:.2f})", (10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(image, f"LSTM: {prediction3} ({confidence3:.2f})", (10, 90), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞ –∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∂–µ—Å—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏
    if evaluation_mode and current_gesture:
        cv2.putText(image, f"Evaluation Mode: {current_gesture}", (10, h - 20), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    return image

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞
def process_video(video_source):
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø–æ–¥—Ö–æ–¥–æ–≤
    metrics = {
        "RF": {"correct": 0, "total": 0, "time": 0},
        "CNN": {"correct": 0, "total": 0, "time": 0},
        "LSTM": {"correct": 0, "total": 0, "time": 0}
    }
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è LSTM
    landmark_history = LandmarkHistory(max_length=15)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    rf_stabilizer = PredictionStabilizer(window_size=stability_window, threshold=stability_threshold)
    cnn_stabilizer = PredictionStabilizer(window_size=stability_window, threshold=stability_threshold)
    lstm_stabilizer = PredictionStabilizer(window_size=stability_window, threshold=stability_threshold)
    
    # –î–ª—è –≤–µ–±-–∫–∞–º–µ—Ä—ã
    if video_source == 0:
        cap = cv2.VideoCapture(0)
        stframe = st.empty()
        
        # –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        col1, col2, col3 = st.columns(3)
        rf_metrics = col1.empty()
        cnn_metrics = col2.empty()
        lstm_metrics = col3.empty()
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫–Ω–æ–ø–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ —Ü–∏–∫–ª–∞
        stop_button_container = st.empty()
        stop_pressed = stop_button_container.button("Stop", key="webcam_stop_button")
        
        # –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        running = True
        
        while cap.isOpened() and running and not stop_pressed:
            ret, frame = cap.read()
            if not ret:
                break
                
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            features, hand_landmarks = extract_hand_features(frame)
            
            prediction1, confidence1 = "Not detected", 0
            prediction2, confidence2 = "Not detected", 0
            prediction3, confidence3 = "Not detected", 0
            
            if features:
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è LSTM
                landmark_history.add(features[:63])  # –¢–æ–ª—å–∫–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
                
                # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è Random Forest
                start_time = time.time()
                raw_prediction1, raw_confidence1 = approach_1_random_forest(features)
                rf_time = time.time() - start_time
                metrics["RF"]["time"] += rf_time
                metrics["RF"]["total"] += 1
                
                # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Random Forest
                prediction1, confidence1 = rf_stabilizer.update(raw_prediction1, raw_confidence1)
                
                # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è CNN
                start_time = time.time()
                raw_prediction2, raw_confidence2 = approach_2_cnn(frame, hand_landmarks)
                cnn_time = time.time() - start_time
                metrics["CNN"]["time"] += cnn_time
                metrics["CNN"]["total"] += 1
                
                # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è CNN
                prediction2, confidence2 = cnn_stabilizer.update(raw_prediction2, raw_confidence2)
                
                # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è LSTM, –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–¥—Ä–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏
                sequence = landmark_history.get_sequence()
                if sequence is not None:
                    start_time = time.time()
                    raw_prediction3, raw_confidence3 = approach_3_lstm(sequence)
                    lstm_time = time.time() - start_time
                    metrics["LSTM"]["time"] += lstm_time
                    metrics["LSTM"]["total"] += 1
                    
                    # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è LSTM
                    prediction3, confidence3 = lstm_stabilizer.update(raw_prediction3, raw_confidence3)
                    
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è LSTM –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏
                    if evaluation_mode and current_gesture:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∂–µ—Å—Ç–æ–º
                        metrics["LSTM"]["total"] += 1
                        if prediction3 == current_gesture:
                            metrics["LSTM"]["correct"] += 1
                
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è RF –∏ CNN –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏
                    if evaluation_mode and current_gesture:
                        # Random Forest
                        metrics["RF"]["total"] += 1
                        if prediction1 == current_gesture:
                            metrics["RF"]["correct"] += 1
                        
                        # CNN
                        metrics["CNN"]["total"] += 1
                        if prediction2 == current_gesture:
                            metrics["CNN"]["correct"] += 1
                    
                    # –ï—Å–ª–∏ –Ω–µ –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
                    elif not evaluation_mode:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å (–±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –≥–æ–ª–æ—Å–æ–≤)
                        predictions = [prediction1, prediction2]
                        if prediction3 != "Not detected" and prediction3 != "Error":
                            predictions.append(prediction3)
                        
                        if len(predictions) >= 2:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –¥–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                            prediction_counts = collections.Counter(predictions)
                            most_common = prediction_counts.most_common(1)
                            
                            if most_common:
                                consensus, count = most_common[0]
                                
                                # –ï—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å–æ–≥–ª–∞—Å–Ω—ã
                                if count >= len(predictions)/2:
                                    # Random Forest
                                    metrics["RF"]["total"] += 1
                                    if prediction1 == consensus:
                                        metrics["RF"]["correct"] += 1
                                    
                                    # CNN
                                    metrics["CNN"]["total"] += 1
                                    if prediction2 == consensus:
                                        metrics["CNN"]["correct"] += 1
                                    
                                    # LSTM (–µ—Å–ª–∏ –∞–∫—Ç–∏–≤–µ–Ω)
                                    if prediction3 != "Not detected" and prediction3 != "Error":
                                        metrics["LSTM"]["total"] += 1
                                        if prediction3 == consensus:
                                            metrics["LSTM"]["correct"] += 1
            else:
                # –ï—Å–ª–∏ —Ä—É–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞, –æ—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä—ã
                landmark_history.clear()
                rf_stabilizer.clear()
                cnn_stabilizer.clear()
                lstm_stabilizer.clear()
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –∫–∞–¥—Ä–µ
            result_frame = display_results(frame, hand_landmarks, prediction1, confidence1, 
                                          prediction2, confidence2, prediction3, confidence3, evaluation_mode, current_gesture)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Streamlit
            result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
            stframe.image(result_frame_rgb, channels="RGB")
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            if metrics["RF"]["total"] > 0:
                rf_accuracy = metrics["RF"]["correct"] / metrics["RF"]["total"]
                rf_avg_time = metrics["RF"]["time"] / metrics["RF"]["total"]
                rf_metrics.markdown(f"""
                ### Random Forest Metrics:
                - Accuracy: {rf_accuracy:.2f}
                - Average time: {rf_avg_time*1000:.2f} ms
                """)
            
            if metrics["CNN"]["total"] > 0:
                cnn_accuracy = metrics["CNN"]["correct"] / metrics["CNN"]["total"]
                cnn_avg_time = metrics["CNN"]["time"] / metrics["CNN"]["total"]
                cnn_metrics.markdown(f"""
                ### CNN Metrics:
                - Accuracy: {cnn_accuracy:.2f}
                - Average time: {cnn_avg_time*1000:.2f} ms
                """)
                
            if metrics["LSTM"]["total"] > 0:
                lstm_accuracy = metrics["LSTM"]["correct"] / metrics["LSTM"]["total"]
                lstm_avg_time = metrics["LSTM"]["time"] / metrics["LSTM"]["total"]
                lstm_metrics.markdown(f"""
                ### LSTM Metrics:
                - Accuracy: {lstm_accuracy:.2f}
                - Average time: {lstm_avg_time*1000:.2f} ms
                """)
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –Ω–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            # –ú—ã –Ω–µ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–Ω–æ–ø–∫—É –≤ —Ü–∏–∫–ª–µ, –∞ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            if stop_pressed:
                running = False
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ CPU
            time.sleep(0.01)
            
        cap.release()
        
    # –î–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
    else:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(video_source.read())
        
        cap = cv2.VideoCapture(tfile.name)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–¥–µ–æ
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
        progress_bar = st.progress(0)
        stframe = st.empty()
        
        # –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        col1, col2, col3 = st.columns(3)
        rf_metrics = col1.empty()
        cnn_metrics = col2.empty()
        lstm_metrics = col3.empty()
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫–Ω–æ–ø–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ —Ü–∏–∫–ª–∞
        stop_button_container = st.empty()
        stop_pressed = stop_button_container.button("Stop", key="video_stop_button")
        
        frame_count = 0
        
        while cap.isOpened() and not stop_pressed:
            ret, frame = cap.read()
            if not ret:
                break
                
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ 3-–≥–æ –∫–∞–¥—Ä–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            if frame_count % 3 == 0:
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
                features, hand_landmarks = extract_hand_features(frame)
                
                prediction1, confidence1 = "Not detected", 0
                prediction2, confidence2 = "Not detected", 0
                prediction3, confidence3 = "Not detected", 0
                
                if features:
                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è LSTM
                    landmark_history.add(features[:63])  # –¢–æ–ª—å–∫–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
                    
                    # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è Random Forest
                    start_time = time.time()
                    raw_prediction1, raw_confidence1 = approach_1_random_forest(features)
                    rf_time = time.time() - start_time
                    metrics["RF"]["time"] += rf_time
                    metrics["RF"]["total"] += 1
                    
                    # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Random Forest
                    prediction1, confidence1 = rf_stabilizer.update(raw_prediction1, raw_confidence1)
                    
                    # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è CNN
                    start_time = time.time()
                    raw_prediction2, raw_confidence2 = approach_2_cnn(frame, hand_landmarks)
                    cnn_time = time.time() - start_time
                    metrics["CNN"]["time"] += cnn_time
                    metrics["CNN"]["total"] += 1
                    
                    # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è CNN
                    prediction2, confidence2 = cnn_stabilizer.update(raw_prediction2, raw_confidence2)
                    
                    # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è LSTM, –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–¥—Ä–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏
                    sequence = landmark_history.get_sequence()
                    if sequence is not None:
                        start_time = time.time()
                        raw_prediction3, raw_confidence3 = approach_3_lstm(sequence)
                        lstm_time = time.time() - start_time
                        metrics["LSTM"]["time"] += lstm_time
                        metrics["LSTM"]["total"] += 1
                        
                        # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è LSTM
                        prediction3, confidence3 = lstm_stabilizer.update(raw_prediction3, raw_confidence3)
                        
                        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è LSTM –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏
                        if evaluation_mode and current_gesture:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∂–µ—Å—Ç–æ–º
                            metrics["LSTM"]["total"] += 1
                            if prediction3 == current_gesture:
                                metrics["LSTM"]["correct"] += 1
                    
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è RF –∏ CNN –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏
                    if evaluation_mode and current_gesture:
                        # Random Forest
                        metrics["RF"]["total"] += 1
                        if prediction1 == current_gesture:
                            metrics["RF"]["correct"] += 1
                        
                        # CNN
                        metrics["CNN"]["total"] += 1
                        if prediction2 == current_gesture:
                            metrics["CNN"]["correct"] += 1
                    
                    # –ï—Å–ª–∏ –Ω–µ –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
                    elif not evaluation_mode:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å (–±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –≥–æ–ª–æ—Å–æ–≤)
                        predictions = [prediction1, prediction2]
                        if prediction3 != "Not detected" and prediction3 != "Error":
                            predictions.append(prediction3)
                        
                        if len(predictions) >= 2:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –¥–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                            prediction_counts = collections.Counter(predictions)
                            most_common = prediction_counts.most_common(1)
                            
                            if most_common:
                                consensus, count = most_common[0]
                                
                                # –ï—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å–æ–≥–ª–∞—Å–Ω—ã
                                if count >= len(predictions)/2:
                                    # Random Forest
                                    metrics["RF"]["total"] += 1
                                    if prediction1 == consensus:
                                        metrics["RF"]["correct"] += 1
                                    
                                    # CNN
                                    metrics["CNN"]["total"] += 1
                                    if prediction2 == consensus:
                                        metrics["CNN"]["correct"] += 1
                                    
                                    # LSTM (–µ—Å–ª–∏ –∞–∫—Ç–∏–≤–µ–Ω)
                                    if prediction3 != "Not detected" and prediction3 != "Error":
                                        metrics["LSTM"]["total"] += 1
                                        if prediction3 == consensus:
                                            metrics["LSTM"]["correct"] += 1
                else:
                    # –ï—Å–ª–∏ —Ä—É–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞, –æ—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ç–æ—Ä—ã
                    landmark_history.clear()
                    rf_stabilizer.clear()
                    cnn_stabilizer.clear()
                    lstm_stabilizer.clear()
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –∫–∞–¥—Ä–µ
                result_frame = display_results(frame, hand_landmarks, prediction1, confidence1, 
                                              prediction2, confidence2, prediction3, confidence3, evaluation_mode, current_gesture)
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Streamlit
                result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
                stframe.image(result_frame_rgb, channels="RGB")
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                if metrics["RF"]["total"] > 0:
                    rf_accuracy = metrics["RF"]["correct"] / metrics["RF"]["total"]
                    rf_avg_time = metrics["RF"]["time"] / metrics["RF"]["total"]
                    rf_metrics.markdown(f"""
                    ### Random Forest Metrics:
                    - Accuracy: {rf_accuracy:.2f}
                    - Average time: {rf_avg_time*1000:.2f} ms
                    """)
                
                if metrics["CNN"]["total"] > 0:
                    cnn_accuracy = metrics["CNN"]["correct"] / metrics["CNN"]["total"]
                    cnn_avg_time = metrics["CNN"]["time"] / metrics["CNN"]["total"]
                    cnn_metrics.markdown(f"""
                    ### CNN Metrics:
                    - Accuracy: {cnn_accuracy:.2f}
                    - Average time: {cnn_avg_time*1000:.2f} ms
                    """)
                    
                if metrics["LSTM"]["total"] > 0:
                    lstm_accuracy = metrics["LSTM"]["correct"] / metrics["LSTM"]["total"]
                    lstm_avg_time = metrics["LSTM"]["time"] / metrics["LSTM"]["total"]
                    lstm_metrics.markdown(f"""
                    ### LSTM Metrics:
                    - Accuracy: {lstm_accuracy:.2f}
                    - Average time: {lstm_avg_time*1000:.2f} ms
                    """)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä–∞
            frame_count += 1
            progress_bar.progress(min(frame_count / total_frames, 1.0))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –Ω–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            # –ú—ã –Ω–µ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–Ω–æ–ø–∫—É –≤ —Ü–∏–∫–ª–µ, –∞ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            if stop_pressed:
                break
            
        cap.release()
        os.unlink(tfile.name)  # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –≤—ã–≤–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–¥—Ö–æ–¥–æ–≤
    if metrics["RF"]["total"] > 0 and metrics["CNN"]["total"] > 0 and metrics["LSTM"]["total"] > 0:
        rf_accuracy = metrics["RF"]["correct"] / metrics["RF"]["total"]
        rf_avg_time = metrics["RF"]["time"] / metrics["RF"]["total"]
        
        cnn_accuracy = metrics["CNN"]["correct"] / metrics["CNN"]["total"]
        cnn_avg_time = metrics["CNN"]["time"] / metrics["CNN"]["total"]
        
        lstm_accuracy = metrics["LSTM"]["correct"] / metrics["LSTM"]["total"]
        lstm_avg_time = metrics["LSTM"]["time"] / metrics["LSTM"]["total"]
        
        st.write("## Final Comparison of Approaches")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        eval_mode_text = "Evaluation with human feedback" if evaluation_mode else "Evaluation with consensus voting"
        st.write(f"**Evaluation Method**: {eval_mode_text}")
        st.write(f"**Total Samples**: RF: {metrics['RF']['total']}, CNN: {metrics['CNN']['total']}, LSTM: {metrics['LSTM']['total']}")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        comparison_data = {
            "Metric": ["Accuracy", "Average time (ms)", "Correct predictions", "Total predictions"],
            "Random Forest": [f"{rf_accuracy:.2f}", f"{rf_avg_time*1000:.2f}", 
                             f"{metrics['RF']['correct']}", f"{metrics['RF']['total']}"],
            "CNN": [f"{cnn_accuracy:.2f}", f"{cnn_avg_time*1000:.2f}", 
                   f"{metrics['CNN']['correct']}", f"{metrics['CNN']['total']}"],
            "LSTM": [f"{lstm_accuracy:.2f}", f"{lstm_avg_time*1000:.2f}", 
                    f"{metrics['LSTM']['correct']}", f"{metrics['LSTM']['total']}"]
        }
        
        st.table(comparison_data)
        
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        best_accuracy = max(rf_accuracy, cnn_accuracy, lstm_accuracy)
        if best_accuracy == rf_accuracy:
            st.write("**Accuracy Conclusion**: Random Forest showed the best accuracy.")
        elif best_accuracy == cnn_accuracy:
            st.write("**Accuracy Conclusion**: CNN showed the best accuracy.")
        else:
            st.write("**Accuracy Conclusion**: LSTM showed the best accuracy.")
            
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏
        best_time = min(rf_avg_time, cnn_avg_time, lstm_avg_time)
        if best_time == rf_avg_time:
            st.write("**Speed Conclusion**: Random Forest is the fastest.")
        elif best_time == cnn_avg_time:
            st.write("**Speed Conclusion**: CNN is the fastest.")
        else:
            st.write("**Speed Conclusion**: LSTM is the fastest.")
        

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
st.sidebar.title("Settings")
source_option = st.sidebar.radio(
    "Select source",
    ["Webcam", "Upload video"]
)

# –†–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
st.sidebar.subheader("Evaluation Mode")
evaluation_mode = st.sidebar.checkbox("Enable Evaluation Mode", value=False, 
                                     help="In evaluation mode, you select the current gesture to measure model accuracy")
current_gesture = None
if evaluation_mode:
    current_gesture = st.sidebar.selectbox("Current Gesture", GESTURE_CLASSES)
    st.sidebar.info("Select the gesture you are currently showing to evaluate model accuracy")
else:
    st.sidebar.info("In automatic mode, model accuracy is calculated based on consensus voting between models")
    st.sidebar.warning("For more accurate evaluation, enable Evaluation Mode and select the gesture you are showing")

# –í—ã–±–æ—Ä –ø–æ–¥—Ö–æ–¥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
st.sidebar.subheader("Select approaches to compare")
compare_rf = st.sidebar.checkbox("Random Forest", value=True)
compare_cnn = st.sidebar.checkbox("CNN", value=True)
compare_lstm = st.sidebar.checkbox("LSTM", value=True)

if not (compare_rf or compare_cnn or compare_lstm):
    st.sidebar.warning("Please select at least one approach to compare")
    compare_rf = True

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
st.sidebar.subheader("Stabilization Settings")
stability_window = st.sidebar.slider("Stability Window Size", 5, 30, 15, 
                                     help="Number of frames used for voting. Higher values make predictions more stable but slower to change.")
stability_threshold = st.sidebar.slider("Stability Threshold", 0.4, 0.9, 0.6, 0.05, 
                                        help="Confidence threshold for changing prediction. Higher values require more consistent predictions.")

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if st.sidebar.button("Restart Application"):
    st.experimental_rerun()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
if source_option == "Webcam":
    process_video(0)
else:
    uploaded_file = st.sidebar.file_uploader("Upload video", type=["mp4", "avi", "mov"])
    if uploaded_file is not None:
        process_video(uploaded_file) 